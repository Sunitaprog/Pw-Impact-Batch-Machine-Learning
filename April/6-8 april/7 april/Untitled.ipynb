{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?\n",
    "\n",
    "Polynomial functions and kernel functions are both used in machine learning algorithms to transform data into a higher-dimensional space in order to make it easier to classify or analyze.\n",
    "\n",
    "Polynomial functions are a type of function that involve raising an input variable to various powers and multiplying by coefficients. Polynomial functions are commonly used in regression analysis, where they can be used to fit a curve to a set of data points. In machine learning, polynomial functions can be used as a basis function to transform data into a higher-dimensional space.\n",
    "\n",
    "Kernel functions, on the other hand, are a general class of functions that take two inputs and return a scalar value. In machine learning, kernel functions are used to compute the similarity between two data points in a feature space. The kernel function essentially measures the degree of similarity between two inputs, and this similarity metric is used to determine how close or far apart the inputs are in the transformed feature space.\n",
    "\n",
    "In many cases, polynomial functions can be used as kernel functions in machine learning algorithms. This is because polynomial functions can be expressed as a dot product of two vectors in a higher-dimensional space. Specifically, the polynomial kernel function is defined as:\n",
    "**K(x, y) = (x^T y + c)^d**\n",
    "\n",
    "where x and y are input vectors, d is the degree of the polynomial, and c is a constant term. This kernel function computes the similarity between two inputs in a higher-dimensional feature space without explicitly transforming the data into that space.\n",
    "\n",
    "In summary, while polynomial functions and kernel functions are different types of functions, they are related in that polynomial functions can be used as kernel functions in machine learning algorithms.\n",
    "\n",
    "## Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
    "\n",
    "To implement a support vector machine (SVM) with a polynomial kernel in Python using Scikit-learn, you can follow these steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=100, n_features=10, n_informative=5, n_classes=2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_svm = SVC(kernel='poly', degree=3, gamma='scale')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='poly')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_svm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = poly_svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we have used the accuracy_score function from the metrics module of Scikit-learn to calculate the accuracy of the model.\n",
    "\n",
    "Overall, these steps show how you can implement a support vector machine (SVM) with a polynomial kernel in Python using Scikit-learn.\n",
    "\n",
    "\n",
    "## Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Support Vector Regression (SVR), the parameter epsilon is a hyperparameter that controls the trade-off between the flatness of the regression function and the degree to which errors are tolerated in the training data. Specifically, epsilon defines a margin of tolerance around the predicted value, within which errors are not penalized.\n",
    "\n",
    "Increasing the value of epsilon in SVR tends to increase the number of support vectors. This is because as the value of epsilon increases, the flatness of the regression function increases and the degree of error tolerance also increases. As a result, more data points are likely to fall within the margin of tolerance, which in turn leads to more support vectors.\n",
    "\n",
    "The number of support vectors in SVR has a direct impact on the complexity of the model and its ability to generalize to new data. In general, a higher number of support vectors can lead to longer training times and potentially overfitting to the training data. On the other hand, a lower number of support vectors can result in a simpler model that may not capture all of the complex relationships in the data.\n",
    "\n",
    "Therefore, the choice of epsilon should be carefully considered to strike a balance between model complexity and accuracy. In practice, the optimal value of epsilon is often determined through a process of cross-validation or grid search over a range of hyperparameter values.\n",
    "\n",
    "## Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?\n",
    "\n",
    "The performance of Support Vector Regression (SVR) is heavily dependent on the choice of hyperparameters such as the kernel function, C parameter, epsilon parameter, and gamma parameter. In this answer, we will discuss each parameter and explain how it works and when you might want to increase or decrease its value.\n",
    " \n",
    "1. **Kernel Function:** The choice of kernel function determines the mapping of the input data to a high-dimensional feature space. The kernel function is specified using the kernel hyperparameter in the SVR object. Scikit-learn provides several options for kernel functions, such as linear, polynomial, and radial basis function (RBF). The choice of kernel function depends on the nature of the data and the problem at hand. In general, the RBF kernel is a good default choice and works well in many scenarios.\n",
    "\n",
    "2. **C Parameter**: The C parameter controls the trade-off between model complexity and training error. It is specified using the C hyperparameter in the SVR object. A smaller value of C will result in a wider margin and a simpler model, while a larger value of C will result in a narrower margin and a more complex model. Increasing the value of C can lead to overfitting, while decreasing the value of C can lead to underfitting. You might want to increase the value of C if the model is underfitting, and decrease the value of C if the model is overfitting.\n",
    "\n",
    "3. **Epsilon Parameter**: The epsilon parameter determines the width of the margin around the predicted value within which errors are not penalized. It is specified using the epsilon hyperparameter in the SVR object. A larger value of epsilon will allow for more error in the model, while a smaller value of epsilon will make the model more sensitive to errors. You might want to increase the value of epsilon if the model is too sensitive to noise, and decrease the value of epsilon if the model is not sensitive enough to noise.\n",
    "\n",
    "4. **Gamma Parameter:** The gamma parameter determines the width of the Gaussian kernel for the RBF kernel function. It is specified using the gamma hyperparameter in the SVR object. A larger value of gamma will result in a narrower kernel and a more complex model, while a smaller value of gamma will result in a wider kernel and a simpler model. Increasing the value of gamma can lead to overfitting, while decreasing the value of gamma can lead to underfitting. You might want to increase the value of gamma if the model is underfitting, and decrease the value of gamma if the model is overfitting.\n",
    "\n",
    "In general, the choice of hyperparameters in Support Vector Regression (SVR) can have a significant impact on the performance of the model. It is highly recommended to test different values of these hyperparameters using techniques such as cross-validation and grid search to find the optimal combination of hyperparameters for the given problem.\n",
    "\n",
    "## Q 5. Assignment:\n",
    "\n",
    "1. Import the necessary libraries and load the dataset.\n",
    "2. Split the dataset into training and testing sets.\n",
    "3. Preprocess the data using any technique of your choice. (e.g. scaling, normalization)\n",
    "4. Create an instance of the SVC classifier and train it on the training data.\n",
    "5. Use the trained classifier to predict the labels of the testing data.\n",
    "6. Evaluate the performance of the classifier using any metric of your choice. (e.g. accuracy, precision, recall, F1-score)\n",
    "7. Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomizedSearchCV to improve its performance.\n",
    "8. Train the tuned classifier on the entire dataset.\n",
    "9. Save the trained classifier to a file for future use.\n",
    "\n",
    "**NOTE: You can use any dataset of your choice for this assignment, but make sure it is suitable for classification and has a sufficient number of features and samples.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the necessary libraries and load the dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split the dataset into training and testing sets\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Preprocess the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Create an instance of the SVC classifier and train it on the training data\n",
    "svc = SVC()\n",
    "svc.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Use the trained classifier to predict the labels of the testing data\n",
    "y_pred = svc.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Evaluate the performance of the classifier using accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=0.1, gamma=10, kernel=linear ..................................\n",
      "[CV] ...... C=0.1, gamma=10, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=0.1, gamma=10, kernel=linear ..................................\n",
      "[CV] ...... C=0.1, gamma=10, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=0.1, gamma=10, kernel=linear ..................................\n",
      "[CV] ...... C=0.1, gamma=10, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=0.1, gamma=10, kernel=linear ..................................\n",
      "[CV] ...... C=0.1, gamma=10, kernel=linear, score=1.000, total=   0.0s\n",
      "[CV] C=0.1, gamma=10, kernel=linear ..................................\n",
      "[CV] ...... C=0.1, gamma=10, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=1.000, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=1.000, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=1.000, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=1.000, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=0.958, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=1, gamma=10, kernel=linear ....................................\n",
      "[CV] ........ C=1, gamma=10, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=1, gamma=10, kernel=linear ....................................\n",
      "[CV] ........ C=1, gamma=10, kernel=linear, score=1.000, total=   0.0s\n",
      "[CV] C=1, gamma=10, kernel=linear ....................................\n",
      "[CV] ........ C=1, gamma=10, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=1, gamma=10, kernel=linear ....................................\n",
      "[CV] ........ C=1, gamma=10, kernel=linear, score=1.000, total=   0.0s\n",
      "[CV] C=1, gamma=10, kernel=linear ....................................\n",
      "[CV] ........ C=1, gamma=10, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=1.000, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=1.000, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=1.000, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=1.000, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=1.000, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=1.000, total=   0.0s\n",
      "[CV] C=10, gamma=10, kernel=linear ...................................\n",
      "[CV] ....... C=10, gamma=10, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=10, gamma=10, kernel=linear ...................................\n",
      "[CV] ....... C=10, gamma=10, kernel=linear, score=1.000, total=   0.0s\n",
      "[CV] C=10, gamma=10, kernel=linear ...................................\n",
      "[CV] ....... C=10, gamma=10, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=10, gamma=10, kernel=linear ...................................\n",
      "[CV] ....... C=10, gamma=10, kernel=linear, score=1.000, total=   0.0s\n",
      "[CV] C=10, gamma=10, kernel=linear ...................................\n",
      "[CV] ....... C=10, gamma=10, kernel=linear, score=1.000, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10],\n",
       "                         'kernel': ['linear']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Tune the hyperparameters of the SVC classifier using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10], 'kernel': ['linear']}\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=3)\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, gamma=0.1, kernel='linear')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Train the tuned classifier on the entire dataset\n",
    "best_svc = grid.best_estimator_\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "best_svc.fit(X_scaled, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Save the trained classifier to a file for future use\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trained_classifier.pkl', 'wb') as file:\n",
    "    pickle.dump(best_svc, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
