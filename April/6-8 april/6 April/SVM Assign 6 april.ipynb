{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. What is the mathematical formula for a linear SVM?\n",
    "\n",
    "A linear support vector machine (SVM) is a type of machine learning algorithm used for binary classification problems. The objective of a linear SVM is to find a hyperplane that separates the data points into two classes in an easy way. The mathematical formula for a linear SVM can be expressed as:\n",
    "\n",
    "**𝑦(𝑖)(𝑤^𝑇𝑥(𝑖) + b) ≥ 1 − 𝜉(𝑖)**\n",
    "\n",
    "Where:\n",
    "\n",
    "1. 𝑥(𝑖) represents the 𝑖-th input data point.\n",
    "2. 𝑦(𝑖) represents the class label of the 𝑖-th input data point, either +1 or -1.\n",
    "3. 𝑤 represents the weight vector.\n",
    "4. 𝑏 represents the bias term.\n",
    "5. 𝜉(𝑖) represents the slack variable that allows for some misclassification of data points.\n",
    "\n",
    "The main objective or the main goal of the linear SVM is to find the optimal values of 𝑤 and 𝑏 that minimize the error and maximize the margin between the hyperplane and the closest data points. It's an optimization problem, which can be solved using quadratic programming or gradient descent.\n",
    "\n",
    "\n",
    "## Q2. What is the objective function of a linear SVM?\n",
    "\n",
    "The objective function of a linear SVM is to find the hyperplane that maximizes the margin between the two classes in a binary classification problem. The margin is defined as the distance between the hyperplane and the closest data points from each class. The optimal hyperplane is the one that has the largest margin, which provides the best separation between the two classes and leads to better generalization performance of the SVM. The objective function of a linear SVM can be expressed as:\n",
    "\n",
    "**minimize: (1/2)||w||^2\n",
    "subject to: 𝑦(𝑖)(𝑤^𝑇𝑥(𝑖) + b) ≥ 1 for i = 1, 2, ..., n**\n",
    "\n",
    "Where:\n",
    "\n",
    "1. 𝑥(𝑖) represents the 𝑖-th input data point.\n",
    "2. 𝑦(𝑖) represents the class label of the 𝑖-th input data point, either +1 or -1.\n",
    "3. 𝑤 represents the weight vector.\n",
    "4. 𝑏 represents the bias term.\n",
    "\n",
    "The first term, **(1/2) ||w||^2** is the regularization term, which penalizes large values of the weight vector w to prevent overfitting. The second term represents the constraint that ensures that each data point is classified correctly and is at least a distance of 1 unit from the hyperplane.\n",
    "\n",
    "The objective function can be solved using techniques such as quadratic programming or gradient descent, which find the optimal values of the weight vector w and the bias term b that minimizes the objective function and maximizes the margin between the two classes.\n",
    "\n",
    "## Q3. What is the kernel trick in SVM?\n",
    "\n",
    "The kernel trick in support vector machines (SVMs) is a technique used to transform the input data into a higher-dimensional feature space without actually computing the coordinates of the data points in that space. This allows SVMs to effectively learn complex decision boundaries that cannot be easily modeled in the original feature space.\n",
    "\n",
    "The basic idea behind the kernel trick is to define a kernel function that computes the dot product of two data points in the higher-dimensional feature space, without actually computing the coordinates of the data points in that space. The kernel function essentially measures the similarity between two data points and provides a way to represent the data in a new feature space that is better suited for classification.\n",
    "\n",
    "There are several types of kernel functions that can be used in SVMs, including:\n",
    "\n",
    "1. **Linear kernel:**\n",
    "K(x, y) = x^T y\n",
    "\n",
    "2. **Polynomial kernel:**\n",
    "K(x, y) = (x^T y + c)^d, where c and d are hyperparameters.\n",
    "\n",
    "3. **Gaussian (or radial basis function) kernel:**\n",
    "K(x, y) = exp(-γ ||x - y||^2), where γ is a hyperparameter.\n",
    "\n",
    "4. **Sigmoid kernel:**\n",
    "K(x, y) = tanh(αx^T y + c), where α and c are hyperparameters.\n",
    "The kernel trick allows SVMs to efficiently handle high-dimensional and non-linear data, by computing the dot products in the higher-dimensional feature space using the kernel function. This leads to better generalization performance and allows SVMs to outperform other classification algorithms on many real-world problems.\n",
    "\n",
    "## Q4. What is the role of support vectors in SVM? Explain with an example.\n",
    "\n",
    "Support vectors are the data points that lie closest to the decision boundary in a support vector machine (SVM) algorithm. These points play a crucial role in defining the decision boundary and determining the margin of the SVM.\n",
    "\n",
    "The support vectors are the data points that are closest to the decision boundary, meaning that they have the largest margin. The margin is defined as the distance between the decision boundary and the closest data points from each class. The support vectors are the data points that lie on the margin, and changing their position or removing them would affect the position of the decision boundary and the margin.\n",
    "\n",
    "For example, let's consider a binary classification problem where we want to classify data points into two classes, A and B. We have the following data points:\n",
    "\n",
    "**Class A**: (1, 1), (2, 2), (2, 0)\n",
    "**Class B:** (-1, -1), (-2, -2), (0, -2)\n",
    "\n",
    "We can use a linear SVM to find the decision boundary that separates the two classes. The decision boundary is the hyperplane that has the largest margin between the two classes. In this case, the decision boundary would pass through the points (0, 0) and (1.5, 1.5), and the margin would be the distance between the decision boundary and the closest data points from each class.\n",
    "\n",
    "In this example, the support vectors are the data points (1, 1), (2, 2), (-1, -1), and (-2, -2), which lie on the margin of the SVM. The position of the support vectors determines the position of the decision boundary and the margin of the SVM. In other words, changing the position of any of the support vectors would lead to a different decision boundary and margin.\n",
    "\n",
    "Thus, support vectors play a critical role in SVMs by defining the decision boundary and determining the margin. They are the key data points that need to be identified and used to train the SVM model.\n",
    "\n",
    "## Q5. Illustrate with examples and graphs of Hyperplane, Marginal plane, Soft margin and Hard margin in SVM?\n",
    "\n",
    "**I) Hyperplane:** Consider a binary classification problem where we want to classify data points into two classes, A and B. The data points are shown in the graph below. The red dots represent class A, and the blue dots represent class B.\n",
    "\n",
    "We can use a linear SVM to find the hyperplane that separates the two classes. It's defined by the equation **y=(w1.x1)+(w2.x2)+b,** where w1, w2 are the weights, and b is the bias term.\n",
    "\n",
    "In this example, the hyperplane is shown in black. It separates the two classes and maximizes the margin between them.\n",
    "\n",
    "**II) Marginal plane:** Consider the same binary classification problem as above, but with an additional data point (1, -1) belonging to class B.\n",
    "\n",
    "We can use a linear SVM to find the hyperplane that separates the two classes. However, the new data point in class B is close to the decision boundary, and the hyperplane may not provide a good separation between the two classes. In such cases, we can use a soft margin SVM that allows some data points to be misclassified.\n",
    "\n",
    "To define the soft margin, we need to introduce the marginal plane that is parallel to the hyperplane and passes through the support vectors. The marginal plane provides a buffer zone between the decision boundary and the data points. The width of the buffer zone is determined by the hyperparameters C and ε, which control the trade-off between the margin and the misclassification rate.\n",
    "\n",
    "In this example, the support vectors are the data points (-1, -1) and (1, 1) and the marginal plane is shown in green. The width of the margin is determined by the distance between the hyperplane and the marginal plane, which is twice the value of ε.\n",
    "\n",
    "**III) Soft margin:** Consider the same binary classification problem as above, but with an additional data point (-2, -2) belonging to class A.\n",
    "\n",
    "We can use a soft margin SVM to find the decision boundary that separates the two classes. The decision boundary allows some data points to be misclassified to achieve a better separation between the two classes.\n",
    "\n",
    "In this example, the hyperplane is shown in black, and the support vectors are the data points (-1, -1), (1, 1), and (-2, -2). The margin is determined by the distance between the hyperplane and the marginal plane, which is twice the value of ε.\n",
    "\n",
    "**IV) Hard margin:** Consider a binary classification problem where we want to classify data points into two classes, A and B. The data points are linearly separable.\n",
    "\n",
    "We can use a hard margin SVM to find the hyperplane that separates the two classes with no misclassification. A hard margin SVM requires the data to be linearly separable, and it does not allow any data points to be misclassified.\n",
    "\n",
    "In this example, the hyperplane is shown in black, and it separates the two classes with no misclassification. The margin is maximized, and the distance between the hyperplane and the support vectors is equal on both sides.\n",
    "\n",
    "## Q6. SVM Implementation through Iris dataset.\n",
    "\n",
    "1. Load the iris dataset from the scikit-learn library and split it into a training set and a testing set.\n",
    "2. Train a linear SVM classifier on the training set and predict the labels for the testing set.\n",
    "3. Compute the accuracy of the model on the testing set.\n",
    "4. Plot the decision boundaries of the trained model using two of the features.\n",
    "5. Try different values of the regularisation parameter C and see how it affects the performance of the model.\n",
    "\n",
    "**BONUS TASK: Implement a linear SVM classifier from scratch using Python and compare its performance with the scikit-learn implementation**.\n",
    "\n",
    "Here is your Python code for the Support Vector Machine (SVM) Implementation through Iris dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data[:, :2], iris.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, kernel='linear')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a linear SVM classifier on the training set\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the testing set\n",
    "y_pred = svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 2, 2, 1, 1, 2, 0, 1,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy of the model on the testing set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the decision boundaries of the trained model using two of the features\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
    "Z = svm.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, s=20, edgecolor='k')\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute thr Accuracy\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.88      0.78      0.82         9\n",
      "           2       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.90      0.90      0.90        30\n",
      "weighted avg       0.90      0.90      0.90        30\n",
      "\n",
      "[[10  0  0]\n",
      " [ 0  7  2]\n",
      " [ 0  1 10]]\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different values of the regularisation parameter C and see how it affects the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel':['linear']\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=GridSearchCV(SVC(),param_grid=param_grid,refit=True,cv=5,verbose=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.708, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.708, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.792, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.708, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.708, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.792, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.708, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.708, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.792, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.708, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.708, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.792, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
      "[CV] .. C=0.1, gamma=0.0001, kernel=linear, score=0.708, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
      "[CV] .. C=0.1, gamma=0.0001, kernel=linear, score=0.708, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
      "[CV] .. C=0.1, gamma=0.0001, kernel=linear, score=0.792, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
      "[CV] .. C=0.1, gamma=0.0001, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=linear ..............................\n",
      "[CV] .. C=0.1, gamma=0.0001, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=0.708, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.708, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.708, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.708, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV] .... C=1, gamma=0.0001, kernel=linear, score=0.708, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV] .... C=1, gamma=0.0001, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV] .... C=1, gamma=0.0001, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV] .... C=1, gamma=0.0001, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV] .... C=1, gamma=0.0001, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=0.667, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.667, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.667, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.667, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV] ... C=10, gamma=0.0001, kernel=linear, score=0.667, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV] ... C=10, gamma=0.0001, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV] ... C=10, gamma=0.0001, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV] ... C=10, gamma=0.0001, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV] ... C=10, gamma=0.0001, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=100, gamma=1, kernel=linear, score=0.667, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=100, gamma=1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=100, gamma=1, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=100, gamma=1, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=100, gamma=1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.667, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.667, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.667, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
      "[CV] .. C=100, gamma=0.0001, kernel=linear, score=0.667, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
      "[CV] .. C=100, gamma=0.0001, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
      "[CV] .. C=100, gamma=0.0001, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
      "[CV] .. C=100, gamma=0.0001, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=linear ..............................\n",
      "[CV] .. C=100, gamma=0.0001, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
      "[CV] ...... C=1000, gamma=1, kernel=linear, score=0.667, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
      "[CV] ...... C=1000, gamma=1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
      "[CV] ...... C=1000, gamma=1, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
      "[CV] ...... C=1000, gamma=1, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=linear ..................................\n",
      "[CV] ...... C=1000, gamma=1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
      "[CV] .... C=1000, gamma=0.1, kernel=linear, score=0.667, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
      "[CV] .... C=1000, gamma=0.1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
      "[CV] .... C=1000, gamma=0.1, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
      "[CV] .... C=1000, gamma=0.1, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=linear ................................\n",
      "[CV] .... C=1000, gamma=0.1, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
      "[CV] ... C=1000, gamma=0.01, kernel=linear, score=0.667, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
      "[CV] ... C=1000, gamma=0.01, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
      "[CV] ... C=1000, gamma=0.01, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
      "[CV] ... C=1000, gamma=0.01, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=linear ...............................\n",
      "[CV] ... C=1000, gamma=0.01, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV] .. C=1000, gamma=0.001, kernel=linear, score=0.667, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV] .. C=1000, gamma=0.001, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV] .. C=1000, gamma=0.001, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV] .. C=1000, gamma=0.001, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=linear ..............................\n",
      "[CV] .. C=1000, gamma=0.001, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
      "[CV] . C=1000, gamma=0.0001, kernel=linear, score=0.667, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
      "[CV] . C=1000, gamma=0.0001, kernel=linear, score=0.750, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
      "[CV] . C=1000, gamma=0.0001, kernel=linear, score=0.875, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
      "[CV] . C=1000, gamma=0.0001, kernel=linear, score=0.833, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=linear .............................\n",
      "[CV] . C=1000, gamma=0.0001, kernel=linear, score=0.750, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['linear']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.88      0.78      0.82         9\n",
      "           2       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.90      0.90      0.90        30\n",
      "weighted avg       0.90      0.90      0.90        30\n",
      "\n",
      "[[10  0  0]\n",
      " [ 0  7  2]\n",
      " [ 0  1 10]]\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "y_pred1=grid.predict(X_test)\n",
    "print(classification_report(y_test,y_pred1))\n",
    "print(confusion_matrix(y_test,y_pred1))\n",
    "print(accuracy_score(y_test,y_pred1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is your Python code for the BONUS TASK of Support Vector Machine (SVM) Implementation through Iris dataset where we're going to implement a linear SVM classifier from scratch using Python and compare its performance with the scikit-learn implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LinearSVM:\n",
    "    def __init__(self, lr=0.01, epochs=1000, C=1):\n",
    "        self.lr = lr # learning rate\n",
    "        self.epochs = epochs # number of epochs\n",
    "        self.C = C # regularization parameter\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        y_ = np.where(y <= 0, -1, 1)\n",
    "        \n",
    "        # initialize weights and bias\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "        \n",
    "        # gradient descent\n",
    "        for epoch in range(self.epochs):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                condition = y_[idx] * (np.dot(x_i, self.w) - self.b) >= 1\n",
    "                if condition:\n",
    "                    self.w -= self.lr * (2 * self.C * self.w)\n",
    "                else:\n",
    "                    self.w -= self.lr * (2 * self.C * self.w - np.dot(x_i, y_[idx]))\n",
    "                    self.b -= self.lr * y_[idx]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.w) - self.b\n",
    "        return np.sign(linear_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of scratch model: 0.30\n",
      "Accuracy of scikit-learn model: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data[:, :2], iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear SVM classifier from scratch on the training set\n",
    "svm_scratch = LinearSVM(lr=0.01, epochs=1000, C=1)\n",
    "svm_scratch.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the testing set using the scratch implementation\n",
    "y_pred_scratch = svm_scratch.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the scratch model on the testing set\n",
    "accuracy_scratch = accuracy_score(y_test, y_pred_scratch)\n",
    "print(f\"Accuracy of scratch model: {accuracy_scratch:.2f}\")\n",
    "\n",
    "# Train a linear SVM classifier using scikit-learn on the training set\n",
    "svm_sklearn = SVC(kernel='linear', C=1)\n",
    "svm_sklearn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the testing set using the scikit-learn implementation\n",
    "y_pred_sklearn = svm_sklearn.predict(X_test)\n",
    "\n",
    "# Compute the accuracy of the scikit-learn model on the testing set\n",
    "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
    "print(f\"Accuracy of scikit-learn model: {accuracy_sklearn:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
